# 分布式理论系列

## 1、从ACID到CAP到BASE

### 1.1 事务的四个特性

* 原子性

  一个事务中所有的操作，要么全部执行成功，要么全部回滚

* 一致性

  1、一个事务执行前后，数据库都必须处于一致性状态。

  2、事务的原子性并不能保证一致性，在多个并发事务的前提下，即使保证每一个事务的原子性，也不能保证数据库的一致性。例：两个事务分别给A账号充钱，但有可能一个事务的结果会覆盖另一个事务的结果，而不是在另一个事务的基础上加成。

  3、一致性需要数据库的隔离性和加锁来保证

  **总结：**一致性就是两个事务并发对一个值操作的情况下，一个事务操作后的值，会被另一个事务覆盖

* 隔离性

  在并发环境中，并发的事务是相互隔离的，即一个事务内部操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务之间不能相互干扰。

* 持久性

  一个事务一旦提交成功，它对数据库的修改是永久性的，即使宕机，只要数据库能重写启动，就能恢复到事务成功时的状态。通过归档日志和联机日志和undo表空间保证

  1. 延时持久：事务提交后将日志先写到缓存中，就返回成功信号，之后再异步的写到磁盘中
  2. 立即持久：事务提交后，日志立即写到磁盘中，写入完成后，才返回事务提交成功信号

### 1.2 事务的隔离级别

* 读未提交

  事务读取的是当前行，会尝试脏读

* 读已提交

  事务读取的是快照中最新的记录，不会产生脏读，但事务中的两次读取，读取到的数据可能不一样，因为另一个事务可能更新了快照中的最新记录了

* 可重复读

  事务读取的是，事务开始时小于等于tx_id的最大的快照，这样事务中的多次读取读的都是同一个快照，但还是会出现**幻读**

  * 同一个事务先读取一段数据，再对其中的一个数据进行更新，有可能更新的行数为0 
  * 因为事务读取的是快照，而更新的是当前行，有可能当前行数据已经被别的事务改变
  * 可以通过 select for update，对读取的事务加排他锁，这样读取的就是当前行了，且当前不能被修改了，**注意：**只有RR级别的for update才会是间隙锁，其它级别只锁已有数据

* 串行化：读取的是当前行，且隐式的加了共享锁



### 1.3 CAP

1. 放弃P：放弃分区容错性，则放弃了分布式，放弃了系统的可扩展性
2. 放弃A：放弃可用性，遇到分区故障时，受影响的服务需要等待一定时间，在此期间无法对我提高服务，即不可用
3. 放弃C：放弃一致性，保证数据的最终一致性，在一个时间窗口内，数据可能不一致



### 1.4 BASE

基于CAP定理演化而来，核心思想是，即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性

1. Basically Available（基本可用）

   指分布式系统在出现不可预测的故障时，允许损失部分可用性

   * 当出现故障时，响应时间增加，正常情况下在线搜索引擎需要在0.5s内返回结果，但由于出现了故障（系统部分机房发生断电或断网故障），查询结果的响应时间增加到1-2s
   * 当流量高峰期时，屏蔽一些功能以保证核心功能和系统的稳定（服务降级），如一个电子商务平台，由于活动期间，购物流量激增，为了保护购物系统的稳定性，部分消费者可能会被引导到以恶搞降级页面

2. Soft state（软状态）

   允许系统在不同节点的数据副本之间进行数据同步的过程存在延迟，即数据一段时间内存在不一致的状态

3. Eventually consistent（最终一致性）

   强调系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态，有一个数据不一致的时间窗口；是弱一致性的特例：系统不能保证后续访问返回更新的值



## 2、2PC到3PC到Paxos到Raft到ISR

### 2.1 两类一致性（操作原子性和副本一致性）

* 2PC/3PC协议用于保证属于多个数据分片上的操作的原子性。这些数据分片可能分布在不同的服务器上，2PC/3PC保证多台服务器上的操作要么全部成功，要么全部失败
* Paxos协议用于保证同一个数据分片的多个副本之间的数据一致性

### 2.2 2PC（阻塞、数据不一致、单点问题）

1. 提交事务请求（投票阶段）

   1. 事务询问

      协调者向所有的参与者**发送事务内容**，询问是否可以**执行事务提交操作**，并开始等待各参与者的响应

   2. 执行事务

      各参与者执行事务操作（，并将undo和redo信息计入事务日志中）

   3. 反馈执行事务的情况

      参与者先协调者反馈事务执行情况，成功返回YES，失败返回NO

2. 执行事务提交（执行阶段）

   1. 所有参与者返回YES
      1. 协调者向所有参与者发出commit请求
      2. 参与者接收到commit请求后，正式提交事务，完成后释放占用资源
      3. 参与者完成事务提交后，向协调者发送ACK信息
      4. 协调者收到所有参与者反馈的ACK消息后完成事务
   2. 任何一个参与者返回NO，中断事务
      1. 协调者向参与者节点发出Rollback请求
      2. 参与者接收到rollback请求后，利用undo信息执行事务回滚操作，并在完成回滚后释放占用的资源
      3. 参与者完成事务回滚后，向协调者发送ACK信息
      4. 协调者接收到所有参与者的ACK信息后，完成事务中断



### 2.3 3PC（解决2PC的阻塞（超时自动提交或中断），但是仍有数据不一致的情况）

1. CanCommit

   1. 事务询问

      协调者向各个参与者发送**包含事务内容**的CanCommit请求，询问是否可以执行事务提交操作，并开始等待各参与者的响应

   2. 参与者收到CanCommit请求后，认为可以顺利执行事务，反馈YES，进入预备状态，否则反馈NO

2. PreCommit

   1. 如果协调者收到的反馈都是YES，执行事务预提交

      1. 协调者向参与者发送PreCommit请求，进入prepared阶段

      2. 参与者接收到PreCommit请求后，执行事务操作

      3. 参与者如果执行事务成功，向协调者发送ACK响应，同时等待最终指令，提交或终止

   2. 如果有任意一个参与者发送的是NO，执行事务中断

      1. 协调者向所有参与者发送abort请求

      2. 参与者收到协调者的abort请求或等待超时，参与者都中断事务

3. DoCommit

   A：提交

   1. 协调者收到所有参与者的ack响应，进入提交阶段，先所有参与者发送doCommit请求
   2. 参与者收到doCommit请求后，正式提交事务，释放占用资源
   3. 向协调者发送ACK信息
   4. 协调者收到所有参与者的ack信息，完成事务

   B：中断

   1. 若任意一个参与者反馈NO或协调者等待超时，向参与者发送中断请求
   2. 参与者接收到中断请求后，利用undo日志执行事务回滚，释放占用资源
   3. 完成后滚之后，先协调者发送ACK信息
   4. 协调者收到所有参与者的ACK信息后，中断事务

   

### 2.4 **2PC故障情况分析**

1. **协调者正常，参与者宕机**

- 发生在第二阶段：无论协调者发起的是提交还是终止，那宕机的参与者在重启之后，都将执行对应操作，不存在不一致情况。**当存在阻塞问题啊，这里的阻塞无法避免**

- 发生在第一阶段：由于协调者无法收集到所有参与者的反馈，**会陷入阻塞情况，这种阻塞可以通过超时机制避免**

  **解决方法**：引入超时机制

  - 超过指定时间未收到反馈，事务失败，向所有节点发送终止事务请求。
  - 宕机的节点启动后，收到终止事务请求，该事务失败。

  **小结：**由于协调者没挂，无论参与者是否宕机，都可以从协调者这里获取正确的状态 ，保持数据一致性

1. **协调者宕机，参与者正常**

   无论处于哪个阶段，由于协调者宕机，无法发送提交请求，所有处于执行了操作但是未提交状态的参与者 **都会陷入阻塞情况** 

   **解决方法：**引入协调者备份，同时协调者需要记录操作日志

   - 当检测到协调者宕机一段时间后，协调者备份取代协调者，并读取操作日志，向所有参与者询问状态。
   - 如果是在第一阶段，则继续操作，都是YES，则发送commit
   - 如果是在第二阶段，只可能是commit和roolback的其中一个状态，所以向没提交的发送同样的状态，保持数据一致

2. **协调者和参与者都宕机了**（协调者的状态丢失了，向参与者问，但是参与者也丢失了）

   首先通过协调者备份，恢复协调者，**通过日志找到未完成的事务**，对参与者发起询问。由于**参与者存在宕机**，又3种情况

   1. 存在commit或abort（只可能是一种），指执行相应操作
   2. 存在未开始的节点，说明没有节点到第二阶段，可以直接终止，或者继续事务
   3. 为宕机的节点都是prepare状态，则无法判断宕机节点的状态，可能已经接受了协调者的commit/roolback并成功执行，所以很糟糕
      1. 如果宕机节点都是prepare或未开始，没问题
      2. 如果宕机节点是commit/abort，则该节点事务已结束，必须对其它节点执行相应操作，**但是不知道节点什么状态，除非重新启动**

   **小结：**当协调者和参与者都宕机时，并且未宕机的都是**prepare**状态，则无法解决问题，**只能等参与者恢复，并确认参与者状态**



### 关键！paxos解决单点问题

**关键！：**只要解决协调者单点问题就行，用paxos协议，做多个协调者，只有超过半数的协调者都接收到了相同的信息，才向参与者返回。**这样协调者的信息肯定不会丢失**



### 2.5 2PC与3PC异同

1. 2pc在第一阶段就执行对应操作（资源被锁定），而第二阶段是提交
2. 3pc在第一阶段只是询问能否提交，并不锁定资源；第二阶段再锁定资源执行对应操作；第三阶段是提交
3. 3pc如果 **第二阶段执行后**，超过一定时间未收到**协调者信息**，会**自动提交**
4.  **关键：**第3点，**如果2pc就不能设置自动提交**，因为当前节点不知道其它节点能不能运行事务，而3pc因为过了第一阶段，说明所有节点都有能力执行，所有可以自动提交，但是也不一定

### 2.6 3PC故障情况分析

只考虑协调者和参与者都宕机的情况，其它情况和2pc一样

1. 存在commit或abort，执行相应操作
2. 如果有节点是CanCommit，说明**事务肯定没提交**，直接终止
3. 未宕机的都是**PreCommit**状态。
   1. 如果宕机参与者是**PreCommit**状态，重启后会收到COMMIT消息，没问题
   2. 如果是commit状态，也没问题
   3. 如果是abort状态，**由于其它节点变成了commit**（第二阶段后，参与者未接收协调者消息会自动提交），出现状态不一致
   4. 如果宕机节点是`CanCommit`状态，还未收到协调者的PREPARE消息，这时它只可能是返回YES，重启后收到PREPARE和COMMIT后，状态也正确



**3pc只是通过增加延时，减少了造成状态不一致的概率，没有解决根本问题**

### 2.7 总结

1、3pc再参与者**完成了第二阶段的事务后**，**使用了自动提交**的方式解决了2pc中参与者无法判断状态需要不断等待的情况，提高了服务的可用性。

2、但是比2pc多了一个**询问**步骤，增加了延时。

3、同时3pc可能存在网络问题，当协调者准备发送abort时，网络出问题了，参与者会自动提交，导致数据不一致

4、3pc并没有解决2pc参与者和协调者同时宕机时的问题，只是做了自动提交，提升了服务的可用性

5、而2pc不能做自动提交！因为2pc如果自动提交，错误性会更大，因为当前节点都不知道其它节点能不能提交呢（3pc在询问阶段做了保证）

6、综上，2pc延迟低，但是参与者故障后可能会阻塞；3pc可用性高，但可能因为网络问题导致数据不一致，且延迟高一点点

7、 **关键：完全不必要用3pc，首先根本没有解决数据不一致性的问题，我们只要通过paxos协议保证协调者有多个副本，不会宕机，就可以了。但是网络问题也是一个很头疼的问题**



### 2.8 Basic Paxos 日志同步持久化

**需求：**在N个Server机群上，持久化数据库或文件系统的操作日志，并为每条日志分配连续递增的logID，且运行多个客户端向集群的**任意一个阶段发送日志同步请求**。只要有超过半数server正常服务，并且相互通信，那么这个机器可以持续的提供日志持久化和查询服务

**问题**：当有两个节点分配到同一个LogID时，才需要进行Paxos流程，统一持久化一个节点的LogID对应的内容，另一个节点重新获取LogID



**步骤：**

1、 **获取logID：**当前节点先其它节点请求它们目前的最大logID，选择最大的LogID+1，作为本次持久化日志的logID，可见不能保证logID的唯一性，需要执行paxos流程，选择一个节点

2、**产生proposalID：**产生全局唯一且递增的proposalID，保证同一个server后产生的ProposalID一定大于之前产生的，且最好保证不同server后产生的ID，也大于其它server之前产生的ID

3、**Prepare阶段：**

 	1. proposer准备好proposalID后，将proposalID作为“提案（proposal）”发送给所有的acceptor
		2. acceptor接收到proposer的提案后
      	1. 如果没有response过proposalID大于等于当前Proposal的，且**也没有“接受（accept）”过propoaslID大于当前proposal的**（暂时没看懂），才可以response，并承诺不再accept那些proposalID小于当前proposal的
      	2. 如果已经accept过proposal，那么连同proposalID最大的日志内容一同response。为了在宕机恢复后也能满足，要在response之前，将proposalID和内容写到本地磁盘

4、 **Accept请求阶段：**

1. Proposer收集到majority的response后，来决定后续是否将要发出accept请求
   1. 如果majority的response中的日志内容都为空，那么发出accept并携带当前的日志内容
   2. 如果有任意一个response中有日志内容，说明其它日志可能已经在majority上持久化了，**回退到第一步重新获取LogID**

5、 **Accept处理阶段：**

1. Acceptot接收到proposer的accept请求之后
   1. 如果曾经response过的proposalID大于等于当前的proposal，则说明LogID已经被更大的proposal并发执行，当前Proposal会被覆盖，**回复proposer要去回退到第一步，重新获取LogID**（都到处理阶段了，还被重新返回）
   2. 如果没有，则将proposal日志内容连同proposalID一起写入本地磁盘，回复proposer成功。**当Proposer收到majority的回复成功后，说明日志已经成功在集群上持久化，可以返回客户端消息了**



**4次网络延迟：**

1. 获取LogID
2. prepare阶段，proposer向acceptor发送proposalID
3. accept请求阶段，propser收到acceptor的回应
4. accept处理阶段，acceptor接收到了日志内容

**两次磁盘写入：**

1. prepare阶段，acceptor收到proposalID，将其写入磁盘
2. accept处理阶段，acceptor收到日志内容，将其写入磁盘



### 2.9 Multi-Paxos 日志同步持久化

在Paxos集群中利用Paxos协议选举唯一的leader ，即leader有效期内不会有其他server提出的议案 ，LogID直接由leader产生，然后直接执行accept，得到多数派确认即表示redolog同步成功

1、首先，Multi-Paxos协议并不假设全局必须只能有唯一的leader来生成日志，它允许有多个“自认为是leader的server”来并发生成日志，这样的场景即退化为Basic-Paxos

2、Multi-Paxos可以简单的理解为，经过一轮的Basic-Paxos，成功得到多数派accept的proposer即成为leader（这个过程称为leader Elect），之后可以通过lease机制保持这个leader的身份，使得其它propser不再发起提案，在leader任期中，没有并发冲突，所以不需要向多数派询问LogID,直接执行accept阶段即可

3、在leader任期内投票的所有日志将携带有相同的proposalID ，acceptor应答prepare成功的消息之前要先将这次prepare请求所携带的proposalID持久化到本地 

**步骤：**

1、leader的产生

由于多个server并发执行leader Elect，可能出现两个server在相近的时间内



### 2.10 Raft协议

1、三个角色：follower、candidate、leader

最开始大家都是follower，当follower监听不到leader时，就可以自己成为candidate，发起投票

2、**leader选举**：timeout限制

1. 每个follow都有一个timeout时间，当超过timeout时间，还没收到leader的心跳，则成为candidate，发起投票
2. 首先自己投自己，再向其它节点发送投票请求
3. 如果其它节点还没开始发起投票，则投它，且重置timeout时间
4. 如果一个candidate得到了大多数的投票，则成为leader
5. 成为leader后要定时发送信息和follower保持心跳
6. 若心跳没了，再一次选择leader

**注意：**如果在同一时刻，有两个candidate同时发起投票，且得到了相同的票数。这样形成不了多数派，则所有节点继续等待下一次timeout，重新投



3、**日志的复制**

1. 客户端向leader请求日志处理
2. leader首先向follow发送日志复制请求，follow执行成功向leader发送ack信息
3. leader收到大多数follow的ack信息，确认日志已成功持久化，再执行持久化，并返回客户端执行成功，并向follow发出执行成功信号

**问题：**

1. 如果这一过程中，发生了网络分区或通信故障，使leader不能访问大多数follower，那么leader只能正常更新它能访问的那些follower
2. 然而这是客户端向这个leader节点发送日志处理请求时，由于这个leader得不到多数派的ACK信息，就不能commit，返回客户端请求
3. 而大多数服务器follower接收不到leader的心跳，会重新选举一个候选者作为leader，然后这个leader作为代表于外界打交道
4. 如果这是故障恢复了，那么原先的leader会发现新的最高投票的leader，重新变成follower,在失联阶段这个老leader任何更新都要回滚，接受新的leader的新的更新





参考：

https://segmentfault.com/a/1190000004474543

http://blog.51cto.com/ultrasql/1631861

https://blog.csdn.net/Lnho2015/article/details/78685503

http://thesecretlivesofdata.com/raft/ 非常推荐！

https://mp.weixin.qq.com/s?__biz=MjM5MDg2NjIyMA==&mid=203607654&idx=1&sn=bfe71374fbca7ec5adf31bd3500ab95a&key=8ea74966bf01cfb6684dc066454e04bb5194d780db67f87b55480b52800238c2dfae323218ee8645f0c094e607ea7e6f&ascene=1&uin=MjA1MDk3Njk1&devicetype=webwx&version=70000001&pass_ticket=2ivcW%2FcENyzkz%2FGjIaPDdMzzf%2Bberd36%2FR3FYecikmo%3D

https://angus.nyc/2012/paxos-by-example/